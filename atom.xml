<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Yuchao Yuan</title>
  
  <subtitle>Keep It Simple, Stupid</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://yuchaoy.github.io/"/>
  <updated>2022-08-04T01:56:04.341Z</updated>
  <id>https://yuchaoy.github.io/</id>
  
  <author>
    <name>Yuchao Yuan</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Hello, Wangjing!</title>
    <link href="https://yuchaoy.github.io/2022/08/04/Hello-Wangjing/"/>
    <id>https://yuchaoy.github.io/2022/08/04/Hello-Wangjing/</id>
    <published>2022-08-04T01:55:30.000Z</published>
    <updated>2022-08-04T01:56:04.341Z</updated>
    
    <summary type="html">
    
      
      
        
        
          
        
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>Distributed Deep Learning with Horovod</title>
    <link href="https://yuchaoy.github.io/2019/12/09/Horovod/"/>
    <id>https://yuchaoy.github.io/2019/12/09/Horovod/</id>
    <published>2019-12-09T02:05:57.000Z</published>
    <updated>2019-12-09T02:17:11.084Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;看完了一波分布式深度学习原理，并尝试使用pytorch实现本地两台gpu服务器(各4张卡)之间的通信，结果屡试屡败，太有挫败感，不得已弃之使用人人称道的Horovod。也是在这个时候比较系统地学习了一遍docker，并使用docker成功搭建好了基于Horovod的分布式深度学习环境。下面首先介绍分布式深度学习多机训练机制，后再介绍如何使用Horovod搭建多机训练平台。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Coding" scheme="https://yuchaoy.github.io/categories/Coding/"/>
    
      <category term="Distributed Deep Learning" scheme="https://yuchaoy.github.io/categories/Coding/Distributed-Deep-Learning/"/>
    
    
      <category term="Distributed Deep Learning" scheme="https://yuchaoy.github.io/tags/Distributed-Deep-Learning/"/>
    
      <category term="Horovod" scheme="https://yuchaoy.github.io/tags/Horovod/"/>
    
  </entry>
  
  <entry>
    <title>经典无监督方法</title>
    <link href="https://yuchaoy.github.io/2019/11/28/%E7%BB%8F%E5%85%B8%E6%97%A0%E7%9B%91%E7%9D%A3%E6%96%B9%E6%B3%95/"/>
    <id>https://yuchaoy.github.io/2019/11/28/经典无监督方法/</id>
    <published>2019-11-28T13:01:57.000Z</published>
    <updated>2019-11-29T14:21:58.177Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;本文的目的是回顾经典的无监督方法，方便笔者在失忆的时候迅速回忆起来。&lt;/p&gt;
&lt;p&gt;目前包含如下内容：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;PCA&lt;/li&gt;
&lt;li&gt;K-Means Clustering&lt;/li&gt;
&lt;li&gt;NMF&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Spectral Clustering&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;
    
    </summary>
    
    
      <category term="Theory" scheme="https://yuchaoy.github.io/categories/Theory/"/>
    
      <category term="ML" scheme="https://yuchaoy.github.io/categories/Theory/ML/"/>
    
    
      <category term="Unsupervised" scheme="https://yuchaoy.github.io/tags/Unsupervised/"/>
    
  </entry>
  
  <entry>
    <title>Quantization Method In Approximate Nearest Neighbor Search</title>
    <link href="https://yuchaoy.github.io/2019/03/04/QuantizationANN/"/>
    <id>https://yuchaoy.github.io/2019/03/04/QuantizationANN/</id>
    <published>2019-03-04T08:19:52.000Z</published>
    <updated>2019-12-11T08:58:32.229Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;对于一个检索任务：给定一个&lt;em&gt;query&lt;/em&gt; $q \in R^D$，需要在数据集 $X \in R^{N \times D}$ 中找到距离 $q$ 最近的样本，距离度量函数 $d$ 一般使用欧式距离。&lt;/p&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;
NN(q) = \arg \min\limits_{x \in X} d(q, x) \tag {1}&lt;/script&gt;&lt;p&gt;想要解决这个问题，最朴素的办法是使用 &lt;strong&gt;&lt;em&gt;Exact Search&lt;/em&gt;&lt;/strong&gt;，穷举 $q$ 到 $N$ 个样本点之间的距离，这样一定能准确地找到离 $q$ 最近的样本。但由于 &lt;em&gt;Exact Search&lt;/em&gt; 的复杂度是 $O(ND)$，空间复杂度 $O(ND)$，而实际的应用场景中往往需要在&lt;strong&gt;毫秒级&lt;/strong&gt;的响应时间同时对存储空间也有要求，数据规模稍大（million）的情况下便无法应用上。&lt;/p&gt;
    
    </summary>
    
    
      <category term="ANN" scheme="https://yuchaoy.github.io/categories/ANN/"/>
    
      <category term="quantization" scheme="https://yuchaoy.github.io/categories/ANN/quantization/"/>
    
    
      <category term="quantization" scheme="https://yuchaoy.github.io/tags/quantization/"/>
    
  </entry>
  
</feed>
